# **【完全版】マルチモーダルRAGシステム統合開発計画書 (Streamlit版)**

## **1\. はじめに：私たちが目指すもの**

このドキュメントは、テキスト、PDF、画像、CADファイルなど、形式の異なる複数のドキュメントをまとめて知識として取り込み、一つの対話画面から横断的に検索・質問できるAIシステムを、ゼロから構築するための完全な設計・手順書です。

**このシステムの核心的な思想は「モジュール化」です。**

* **parsers（解析担当）**: ファイルの種類ごとに、中身をテキストに変換する専門家。  
* **vector\_store（データベース担当）**: テキストを検索可能な形式で保管・管理する書庫。  
* **rag\_engine（頭脳担当）**: ユーザーの質問を理解し、書庫から最適な情報を探して回答を生成するAI。  
* **app.py（受付・表示担当）**: ユーザーとのやり取りを担うStreamlitのインターフェース。

このように各部品の役割を完全に分離することで、特定の機能を修正・改善したいときに、他の部分に影響を与えることなく安全に作業を進められます。この設計は、コーディングAI（Codex）にとっても理解しやすく、エラーの少ない開発を可能にします。

### **完成形のアーキテクチャ**

【ユーザー】  
    │  
    V  
┌───────────────────────────────┐  
│  Streamlit UI (app.py)       │  
│  \- 複数ファイルの一括アップロード      │  
│  \- ファイルごとのメタデータ入力画面    │  
│  \- チャット形式の質問 & 回答表示     │  
└───────────────────────────────┘  
    │ (ファイル群, 質問)  
    V  
┌───────────────────────────────┐  
│  統合パイプライン (src/main\_processor.py) │  
│  \- ファイルを一つずつ処理ループ        │  
│  \- 種類を判別し、適切な解析担当へ依頼  │  
└───────────────────────────────┘  
    ├─ (テキストファイル) ──────────────────\> ┌──────────────────┐  
    │                                     │ Text Parser      │  
    ├─ (画像/CADファイル) ───────────────\> │ (src/parsers/text\_parser.py) │  
    │                                     └──────────────────┘  
    ├─ (PDF/DOCXファイル) ──────────────\> ┌──────────────────┐  
    │                                     │ Image Parser     │  
    │                                     │ (src/parsers/image\_parser.py) │  
    │                                     └──────────────────┘  
    │                                     ┌──────────────────┐  
    │                                     │ Document Parser  │  
    │                                     │ (src/parsers/doc\_parser.py) │  
    └─────────────────────────────────────\> └──────────────────┘  
    │ (処理済みのテキストチャンク \+ メタデータ)  
    V  
┌───────────────────────────────┐  
│  ベクトルストア (src/vector\_store.py) │  
│  \- ベクトル化 (text-embedding-3-small) │  
│  \- メタデータと共にFAISSへ保存         │  
└───────────────────────────────┘  
    ^  
    │ (検索クエリ)  
    V (検索結果)  
┌───────────────────────────────┐  
│  RAGエンジン (src/rag\_engine.py)   │  
│  \- 期限切れナレッジを検索から除外    │  
│  \- 質問に最適な情報を検索・取得      │  
│  \- LLM (gpt-4.1-mini) で回答を生成    │
└───────────────────────────────┘

## **2\. 安全な開発のための鉄則 (GitHubでの失敗を防ぐために)**

プルリクエストやマージでのエラーは、手順を守ることで確実に減らせます。Codexに指示を出す前に、必ず以下の準備をしてください。

1. **mainは触らない**: mainブランチから、開発の基点となるdevelopブランチを作成します。  
   * git checkout \-b develop  
2. **作業ごとにブランチを切る**: この計画書の**フェーズごと**に、developブランチから新しいブランチを作成します。  
   * 例: git checkout \-b feature/phase1-parsers  
3. **こまめに記録（コミット）**: 一つの関数やファイルが完成するたびに、変更内容を記録します。メッセージは具体的に書きましょう。  
   * 例: git commit \-m "feat: Create text\_parser module with chunking logic"  
4. **プルリクエストで確認**: フェーズの作業が完了したら、developブランチに対してプルリクエストを作成します。ここで変更内容を自分自身でレビューし、問題がなければマージします。この一手間が事故を防ぎます。

## **進捗記録ルール**

開発の進捗は `PROGRESS.md` に記録します。フェーズを一つ完了するごとに、次の書式で追記してください。

```
- YYYY-MM-DD フェーズX: 内容 完了
```

これにより、現在の作業状況を誰でも簡単に確認できるようにします。

## **3\. フェーズ別・詳細実装計画**

ここからがCodexに与える具体的な指示です。一つずつ、順番に実行させてください。

### **フェーズ 0: 環境構築とプロジェクトの土台作り**

**目的**: これから建てる家のための、完璧な基礎と骨組みを用意する。

**具体的な作業指示 (Codex向け):**

1. **プロジェクトディレクトリの作成**: リポジトリのルートにプロジェクトを構成してください。
2. **ディレクトリ構造の初期化**: ルートディレクトリに以下のディレクトリと**空の**ファイルを作成してください。これは、プロジェクトの設計図そのものです。
   ./
   ├── src/  
   │   ├── parsers/  
   │   │   ├── \_\_init\_\_.py  
   │   │   ├── text\_parser.py  
   │   │   ├── image\_parser.py  
   │   │   └── doc\_parser.py  
   │   ├── \_\_init\_\_.py  
   │   ├── main\_processor.py  
   │   ├── vector\_store.py  
   │   ├── rag\_engine.py  
   │   └── utils.py  
   ├── app.py  
   ├── requirements.txt  
   ├── .env  
   └── .gitignore

3. **依存ライブラリの定義**: requirements.txt ファイルに、プロジェクトで使う全てのライブラリを記述してください。  
   \# requirements.txt  
   openai  
   streamlit  
   python-dotenv  
   numpy  
   faiss-cpu  
   langchain  
   tiktoken  
   PyMuPDF  
   python-docx  
   Pillow  
   rank\_bm25

4. **秘密情報の管理**: .env ファイルを作成し、OpenAIのAPIキーを記述してください。  
   \# .env  
   OPENAI\_API\_KEY="ここにあなたのOpenAI APIキーを貼り付けてください"

5. **GitHubへの安全対策**: .gitignore ファイルを作成し、公開してはいけないファイルやディレクトリを指定してください。  
   \# .gitignore  
   .env  
   \_\_pycache\_\_/  
   .idea/  
   .vscode/  
   \*.log  
   data/ \# ベクトルストアの保存先など

6. **環境のセットアップ**: ターミナルで pip install \-r requirements.txt を実行し、必要なライブラリをインストールしてください。

### **フェーズ 1: コア機能のモジュール化（解析担当の育成）**

**目的**: 様々な形式のファイルを解読できる、専門的な「解析担当（パーサー）」を一人ずつ育成する。

**具体的な作業指示 (Codex向け):**

1. **テキストパーサーの作成 (src/parsers/text\_parser.py)**  
   * このファイルに parse\_text(file\_path: str) \-\> list\[str\] という関数を作成してください。  
   * **役割**: テキストファイル（.txt, .md）のパスを受け取り、中身を読み込みます。langchain.text\_splitter.RecursiveCharacterTextSplitter を使って、長文を意味のある塊（チャンク）に分割し、文字列のリストとして返します。  
   * **エラー処理**: try-except FileNotFoundError で、ファイルが見つからない場合にエラーログを出し、空のリスト \[\] を返すようにしてください。  
2. **画像パーサーの作成 (src/parsers/image\_parser.py)**  
   * このファイルに parse\_image(image\_bytes: bytes, client, surrounding\_text: str \= "") \-\> str という関数を作成してください。  
   * **役割**: 画像のバイナリデータ（ファイルパスではない）と、オプションで画像の周辺テキストを受け取ります。OpenAIのgpt-4.1-miniモデルを使い、「この画像は何を説明しているか」を文章で生成して返します。プロンプトには周辺テキストも情報として含め、より文脈に沿った説明を生成させてください。
   * **エラー処理**: try-except openai.APIError で、API呼び出しに失敗した場合にエラーログを出し、空の文字列 "" を返すようにしてください。  
3. **ドキュメントパーサーの作成 (src/parsers/doc\_parser.py)**  
   * このファイルに parse\_document(file\_path: str) \-\> tuple\[list\[str\], list\[dict\]\] という関数を作成してください。  
   * **役割**: PDFやDOCXファイルのパスを受け取ります。PyMuPDF (PDF) や python-docx (DOCX) を使い、ファイルから**全てのテキストブロック**と**全ての画像**を抽出します。  
   * **戻り値**: (テキストブロックのリスト, 画像情報の辞書のリスト) というタプルで返します。画像情報は {"image\_bytes": bytes, "page\_number": int} の形式で、どのページにあったかの情報も保持します。  
   * **エラー処理**: パスワード付きPDFや破損ファイルのエラーを捕捉し、( \[\], \[\] ) という空のタプルを返すようにしてください。

### **フェーズ 2: 統合パイプラインの構築（司令塔の設置）**

**目的**: 様々なファイルを受け取り、適切な解析担当に仕事を割り振る「司令塔（メインプロセッサー）」を設置する。

**具体的な作業指示 (Codex向け):**

1. **メインプロセッサーの作成 (src/main\_processor.py)**  
   * このファイルに process\_file(file\_path: str, metadata: dict, client) \-\> list\[dict\] という中心的な関数を作成してください。  
   * **役割**: アップロードされた**単一の**ファイルのパスと、それに対応するメタデータ（作成者、有効期限など）を受け取ります。  
   * **処理フロー**:  
     1. ファイルの拡張子（.pdf, .txtなど）を判別します。  
     2. 拡張子に応じて、フェーズ1で作成した適切なパーサー関数を呼び出します。  
     3. **PDF/DOCXの場合**: doc\_parser.parse\_document でテキストと画像を両方抽出し、画像はさらに image\_parser.parse\_image に渡してテキスト化します。  
     4. 全ての処理結果を\*\*「テキストチャンク」と「完全なメタデータ」の辞書のリスト\*\*という統一形式にまとめます。各辞書には、元のメタデータに加えて、ファイル名やページ番号などの情報も追加してください。  
   * **戻り値の形式（例）**:  
     \[  
       {  
         "text": "これはドキュメントの1ページ目のテキストです。",  
         "metadata": {  
           "source\_file": "manual.pdf", "page": 1, "type": "text",  
           "author": "Taro Yamada", "expiration\_date": "2025-12-31"  
         }  
       },  
       {  
         "text": "赤いボタンと緑のランプが描かれた回路図。",  
         "metadata": {  
           "source\_file": "manual.pdf", "page": 1, "type": "image",  
           "author": "Taro Yamada", "expiration\_date": "2025-12-31"  
         }  
       }  
     \]

### **フェーズ 3: 統一ベクトルストアの構築（知識の書庫作り）**

**目的**: 全ての知識（テキストチャンクとメタデータ）を一元的に、かつ検索しやすい形で保管する「書庫（ベクトルストア）」を建設する。

**具体的な作業指示 (Codex向け):**

1. **ベクトルストア管理クラスの作成 (src/vector\_store.py)**  
   * VectorStoreManager というクラスを作成してください。  
   * **\_\_init\_\_(self, client, index\_path="data/faiss\_index")**: OpenAIクライアントと、FAISSインデックスの保存先パスを初期化します。  
   * **add\_documents(self, documents: list\[dict\])**:  
     * main\_processor から受け取ったドキュメント辞書のリストをループ処理します。  
     * 各ドキュメントの "text" 部分を text-embedding-3-small を使ってベクトル化します。  
     * ベクトルと、それに対応する**完全なメタデータ**をFAISS（またはChromaDB）に保存します。メタデータも一緒に保存できるライブラリの機能を使ってください。  
   * **search(self, query: str, k: int \= 5, filters: dict \= None) \-\> list\[dict\]**:  
     * 検索クエリをベクトル化します。  
     * FAISSで類似度検索を行います。  
     * **重要**: 検索時にfilters引数を使ってメタデータによる絞り込みができるようにしてください。（例: {"expiration\_date\_gt": "2025-07-29"}）  
     * ヒットしたドキュメントのテキストとメタデータをリストで返します。

### **フェーズ 4: Streamlit UIの実装（受付カウンターの設置）**

**目的**: ユーザーが直感的にファイルを登録し、質問できる、洗練された「受付カウンター（UI）」を設置する。

**具体的な作業指示 (Codex向け):**

1. **メインUIファイルの作成 (app.py)**  
   * streamlit をインポートし、st.set\_page\_config(layout="wide") でレイアウトを設定してください。  
   * st.title("統合ナレッジ検索システム") でタイトルを表示します。  
2. **ナレッジ登録セクションの実装（複数ファイル対応）**  
   * st.header("ナレッジ登録") でセクションを作ります。  
   * **ステップ1: ファイルアップロード**  
     * uploaded\_files \= st.file\_uploader("ファイルを選択", accept\_multiple\_files=True) を設置します。  
   * **ステップ2: ファイルごとのメタデータ入力**  
     * if uploaded\_files: のブロック内で、アップロードされたファイルのリストをループ処理します。  
     * for file in uploaded\_files: の中で、**st.expander(f"ファイル: {file.name}")** を使って、ファイルごとに折りたたみ可能な入力フォームを作成します。  
     * 各expanderの中に、st.text\_input("作成者", key=f"author\_{file.id}") のように、**ファイルごとにユニークなキーを持つ**入力ウィジェットを配置します。（keyが重要です！）  
     * st.date\_input("有効期限", key=f"exp\_date\_{file.id}") も同様に配置します。  
   * **ステップ3: 登録実行**  
     * フォームの外に if st.button("選択したファイルをナレッジに登録"): を設置します。  
     * ボタンが押されたら、st.session\_state から各ファイルのメタデータを収集します。  
     * with st.spinner(...): の中で、アップロードされたファイルを一つずつループし、main\_processor.process\_file と vector\_store.add\_documents を呼び出して処理します。  
     * st.success("登録が完了しました！") で完了を通知します。

### **フェーズ 5: RAGシステムの接続と最終テスト**

**目的**: 全ての部品を繋ぎ合わせ、システムに魂を吹き込む。そして、あらゆる状況を想定したテストを行う。

**具体的な作業指示 (Codex向け):**

1. **RAGエンジンの作成 (src/rag\_engine.py)**  
   * RAGEngine というクラスを作成してください。\_\_init\_\_でVectorStoreManagerとOpenAIクライアントを初期化します。  
   * **answer\_question(self, question: str) \-\> dict**:  
     1. **期限切れフィルタ**: 現在の日付を取得し、vector\_store.search を呼び出す際に、{"expiration\_date\_gt": "現在の日付"} のようなフィルタを必ず渡して、古い情報を除外します。  
     2. ベクトルストアから関連ドキュメントを取得します。  
     3. 取得したドキュメントをコンテキストとして整形し、gpt-4.1-miniに渡すプロンプトを作成します。
     4. LLMから得られた回答と、参考にしたソースドキュメントのリストを辞書 {"answer": "...", "sources": \[...\]} の形式で返します。  
2. **Streamlitのチャット機能の実装 (app.py)**  
   * st.header("チャット") でセクションを作ります。  
   * st.session\_state を使ってチャット履歴を管理・表示する、Streamlitの標準的なチャットUIを実装してください。  
   * ユーザーが質問を入力（st.chat\_input）したら、RAGEngineのanswer\_questionを呼び出し、返ってきた答えとソースをチャット画面に表示してください。  
3. **総合テスト**  
   * 以下のシナリオを一つずつ、丁寧にテストしてください。  
     * 複数（3つ以上）の異なる形式のファイル（txt, pdf, png）を同時にアップロードし、それぞれに異なるメタデータを設定して登録できるか。  
     * 有効期限を昨日付に設定した規約PDFの内容が、今日の質問の回答に含まれないことを確認する。  
     * PDF内の図について「〜の図を見せて」と質問し、AIが生成した図の説明文が回答に含まれるか確認する。  
     * 何もアップロードせずに質問した際に、エラーにならず「ナレッジベースに情報がありません」と応答するか確認する。

この計画書が、あなたのAIアシスタントにとって明確な道標となり、堅牢で高性能なシステムの完成に繋がることを願っています。
